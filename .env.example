# Ollama API (default Ollama local dev server)
OLLAMA_API=http://localhost:11434/api/generate
# ComfyUI base URL (adjust to your ComfyUI setup)
COMFY_API=http://127.0.0.1:8188
# Comfy model name or identifier (optional)
SD_MODEL=stable-diffusion-xl-base-1.0
# Directory for outputs and ChromaDB persistence
OUTPUT_DIR=static/outputs
CHROMA_PERSIST_DIR=./chroma_storage
# sentence-transformers model for embeddings
EMBEDDING_MODEL=nominic-embed--text:latest
